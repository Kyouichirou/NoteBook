
# streamlitç¼“å­˜è®¾ç½®
## Optimize performance with st.cache

#### Important

We're developing new cache primitives that are easier to use and much faster than `@st.cache`. ğŸš€ To learn more, read [Experimental cache primitives](https://docs.streamlit.io/library/advanced-features/experimental-cache-primitives).

æˆ‘ä»¬å¼€å‘äº†æ–°çš„ç¼“å­˜æœºåˆ¶(primitives), ä½¿ç”¨æ›´å®¹æ˜“, è€Œä¸”é€Ÿåº¦æ¯”`@st.cache`é€Ÿåº¦æ›´å¿«, äº†è§£æ›´å¤š, è¯·å‚è€ƒç›¸å…³é¡µé¢(è¯•éªŒä¸­).

Streamlit provides a caching mechanism that allows your app to stay performant even when loading data from the web, manipulating large datasets, or performing expensive computations. This is done with the [`@st.cache`](https://docs.streamlit.io/library/api-reference/performance/st.cache) decorator.

streamlitæä¾›çš„ç¼“å­˜æœºåˆ¶èƒ½ä¸ºä½ çš„appåœ¨æ•°æ®åŠ è½½, æ“ä½œå¤§å‹æ•°æ®é›†æˆ–è€…å…¶ä»–éœ€è¦è€—è´¹ç®—åŠ›çš„æ“ä½œä¸­ä¿æŒé«˜æ•ˆ. åªéœ€è¦ä½¿ç”¨`@st.cache`è£…é¥°å™¨.

When you mark a function with the [`@st.cache`](https://docs.streamlit.io/library/api-reference/performance/st.cache) decorator, it tells Streamlit that whenever the function is called it needs to check a few things:

å½“ä½ åœ¨å‡½æ•°ä¸­ä½¿ç”¨`@st.cache`è£…é¥°å™¨, è¿™æ„å‘³å‘Šè¯‰streamlitåœ¨å‡½æ•°è°ƒç”¨æ—¶, éœ€è¦åšä¸€äº›æ£€æŸ¥:

1. The input parameters that you called the function with
2. The value of any external variable used in the function
3. The body of the function
4. The body of any function used inside the cached function

- è¾“å…¥çš„å‚æ•°
- å‡½æ•°ä¸­ä½¿ç”¨çš„ä»»æ„å¤–éƒ¨å˜é‡
- å‡½æ•°ä¸»ä½“
- å·²ç¼“å­˜å‡½æ•°ä½¿ç”¨çš„å‡½æ•°ä¸»ä½“

If this is the first time Streamlit has seen these four components with these exact values and in this exact combination and order, it runs the function and stores the result in a local cache. Then, next time the cached function is called, if none of these components changed, Streamlit will just skip executing the function altogether and, instead, return the output previously stored in the cache.

å¦‚æœè¿™æ˜¯streamlitç¬¬ä¸€æ¬¡è¿è¡Œ, streamlitå°†ä¼šç¼“å­˜è¿è¡Œçš„ç»“æœåˆ°æœ¬åœ°ç¼“å­˜. ä¸‹æ¬¡å†è¿è¡Œè¯¥å‡½æ•°æ—¶, å‡å¦‚ä¸Šè¿°æåŠçš„å››ä¸ªéƒ¨åˆ†æ²¡æœ‰å‘ç”Ÿå˜åŒ–, streamlitå°†ä¸ä¼šæ‰§è¡Œå‡½æ•°, è€Œæ˜¯ç›´æ¥è¿”å›ä¹‹å‰ç¼“å­˜ä¸­çš„ç»“æœ.

The way Streamlit keeps track of changes in these components is through hashing. Think of the cache as an in-memory key-value store, where the key is a hash of all of the above and the value is the actual output object passed by reference.

streamlité€šè¿‡hashå€¼æ¥åˆ¤æ–­è¿™äº›å†…å®¹æ˜¯å¦å‘ç”Ÿå˜åŒ–. å¯ä»¥è®¤ä¸ºç¼“å­˜åœ¨å†…å­˜ä¸­ä»¥é”®å€¼å¯¹çš„å½¢å¼å­˜åœ¨, é”®æ˜¯ä¸Šè¿°å†…å®¹çš„çš„hashå€¼, å€¼æ˜¯å®é™…è¾“å‡ºç»“æœå¯¹è±¡çš„å¼•ç”¨.

Finally, [`@st.cache`](https://docs.streamlit.io/library/api-reference/performance/st.cache) supports arguments to configure the cache's behavior. You can find more information on those in our [API reference](https://docs.streamlit.io/library/api-reference).

åŒæ—¶, `@st.cache`æ”¯æŒå‚æ•°æ¥é…ç½®ç¼“å­˜çš„è¡Œä¸º, æ›´æ–°ä¿¡æ¯è§APIå‚è€ƒ.

Let's take a look at a few examples that illustrate how caching works in a Streamlit app.

çœ‹ä¸€ä¸‹å…·ä½“çš„ä¾‹å­åœ¨å®é™…ä¸­çš„ä½¿ç”¨

æ³¨: å®˜æ–¹æ–‡æ¡£ä¸‹é¢çš„æ¡ˆä¾‹,  æŠŠä¸€äº›ç®€å•çš„é—®é¢˜è§£é‡Šçš„è¿‡äºå¤æ‚éš¾æ‡‚, ä¸éœ€è¦å®Œå…¨çœ‹å®˜æ–¹çš„è§£é‡Š.

## st.cache

Function decorator to memoize function executions.

| Function signature                                           |                                                              |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| st.cache(func=None, persist=False, allow_output_mutation=False, show_spinner=True, suppress_st_warning=False, hash_funcs=None, max_entries=None, ttl=None) |                                                              |
| Parameters                                                   |                                                              |
| **func** *(callable)*                                        | The function to cache. Streamlit hashes the function and dependent code. éœ€è¦ç¼“å­˜çš„å‡½æ•° |
| **persist** *(boolean)*                                      | Whether to persist the cache on disk. æŒä¹…åŒ–(ç›®å‰åªæ”¯æŒä¸€ä¸ªé€‰é¡¹, æŒä¹…åŒ–åˆ°ç¡¬ç›˜) |
| **allow_output_mutation** *(boolean)*                        | Streamlit shows a warning when return values are mutated, as that can have unintended consequences. This is done by hashing the return value internally.If you know what you're doing and would like to override this warning, set this to True. å¯å˜å¯¹è±¡è¾“å‡ºè­¦å‘Š |
| **show_spinner** *(boolean)*                                 | Enable the spinner. Default is True to show a spinner when there is a cache miss. ç¼“å­˜ä¸¢å¤± |
| **suppress_st_warning** *(boolean)*                          | Suppress warnings about calling Streamlit functions from within the cached function. å¿½ç•¥è°ƒç”¨ç¼“å­˜å‡½æ•°è­¦å‘Š |
| **hash_funcs** *(dict or None)*                              | Mapping of types or fully qualified names to hash functions. This is used to override the behavior of the hasher inside Streamlit's caching mechanism: when the hasher encounters an object, it will first check to see if its type matches a key in this dict and, if so, will use the provided function to generate a hash for it. See below for an example of how this can be used. å“ˆå¸Œå‡½æ•°, å¯ä»¥è‡ªå®šæ‰§è¡Œå“ˆå¸Œçš„å‡½æ•° |
| **max_entries** *(int or None)*                              | The maximum number of entries to keep in the cache, or None for an unbounded cache. (When a new entry is added to a full cache, the oldest cached entry will be removed.) The default is None.ç¼“å­˜æ•°é‡ |
| **ttl** *(float or None)*                                    | The maximum number of seconds to keep an entry in the cache, or None if cache entries should not expire. The default is None.ç¼“å­˜ä¿æŒæ—¶é—´ |

## Example 1: Basic usage

æ¡ˆä¾‹1: åŸºç¡€ä½¿ç”¨

For starters, let's take a look at a sample app that has a function that performs an expensive, long-running computation. Without caching, this function is rerun each time the app is refreshed, leading to a poor user experience. Copy this code into a new app and try it out yourself:

èµ·å§‹, å…ˆçœ‹ä¸€ä¸ªéœ€è¦èŠ±è´¹æ—¶é—´çš„è¡Œä¸º, æ²¡æœ‰ç¼“å­˜, æ¯ä¸€æ¬¡appé¡µé¢åˆ·æ–°, è¿™ä¸ªå‡½æ•°éƒ½éœ€è¦é‡æ–°æ‰§è¡Œä¸€éè¿”å›ç»“æœ, è¿™å¯¹äºç”¨æˆ·ä½“éªŒè€Œè¨€æ˜¯ç›¸å½“ç³Ÿç³•çš„. å¤åˆ¶ä¸‹é¢ä»£ç , äº²è‡ªå°è¯•ä¸€ä¸‹å§.

```python
import streamlit as st
import time

# æ¨¡æ‹Ÿä¸€ä¸ªéœ€è¦è€—è´¹æ—¶é—´çš„æ“ä½œ
def expensive_computation(a, b):
    time.sleep(2)  # ğŸ‘ˆ This makes the function take 2s to run
    return a * b

a = 2
b = 21
res = expensive_computation(a, b)

st.write("Result:", res)
```

Try pressing **R** to rerun the app, and notice how long it takes for the result to show up. This is because `expensive_computation(a, b)` is being re-executed every time the app runs. This isn't a great experience.

å°è¯•æŒ‰ä¸‹`R`è¿”å›app, ä¼šæ³¨æ„åˆ°é¡µé¢éœ€è¦èŠ±è´¹å¾ˆé•¿å®ç°æ¥å‘ˆç°ç»“æœ. è¿™æ˜¯å› ä¸ºæ¯æ¬¡çš„æ‰§è¡Œéƒ½æ˜¯é‡æ–°è¿è¡Œä¸€æ¬¡å‡½æ•°, è¿™æ˜¯éå¸¸èŠ±è´¹æ—¶é—´çš„, è¿™ä¸æ˜¯å¾ˆå¥½çš„ä½“éªŒ.

Let's add the [`@st.cache`](https://docs.streamlit.io/library/api-reference/performance/st.cache) decorator:

æ·»åŠ è£…é¥°å™¨

```python
import streamlit as st
import time

@st.cache  # ğŸ‘ˆ Added this
def expensive_computation(a, b):
    time.sleep(2)  # This makes the function take 2s to run
    return a * b

a = 2
b = 21
res = expensive_computation(a, b)

st.write("Result:", res)
```

Now run the app again and you'll notice that it is much faster every time you press R to rerun. To understand what is happening, let's add an st.write inside the function:

ç°åœ¨å†æ¬¡è¿è¡Œapp, ä½ ä¼šå‘ç°è¿è¡Œçš„é€Ÿåº¦éå¸¸å¿«. æƒ³äº†è§£å‘ç”Ÿäº†ä»€ä¹ˆå˜›, å¢åŠ ä¸€ä¸ª`st.write`åˆ°å‡½æ•°å».

```python
import streamlit as st
import time

@st.cache(suppress_st_warning=True)  # ğŸ‘ˆ Changed this
def expensive_computation(a, b):
    # ğŸ‘‡ Added this
    st.write("Cache miss: expensive_computation(", a, ",", b, ") ran")
    time.sleep(2)  # This makes the function take 2s to run
    return a * b

a = 2
b = 21
res = expensive_computation(a, b)

st.write("Result:", res)
```

Now when you rerun the app the text "Cache miss" appears on the first run, but not on any subsequent runs. That's because the cached function is only being executed once, and every time after that you're actually hitting the cache.

ç°åœ¨å½“ä½ è¿è¡Œè¿™ä¸ªappæ—¶, "Cache miss"è¿™éƒ¨åˆ†çš„å†…å®¹åªä¼šå‡ºç°åœ¨ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶å‡ºç°. è¿™æ˜¯å› ä¸ºç¼“å­˜çš„åŠŸèƒ½, è¿™ä¸ªå‡½æ•°åªæ‰§è¡Œäº†ä¸€é.

#### Note

æ³¨æ„

You may have noticed that we've added the `suppress_st_warning` keyword to the `@st.cache` decorators. That's because the cached function above uses a Streamlit command itself (`st.write` in this case), and when Streamlit sees that, it shows a warning that your command will only execute when you get a cache miss. More often than not, when you see that warning it's because there's a bug in your code. However, in our case we're using the `st.write` command to demonstrate when the cache is being missed, so the behavior Streamlit is warning us about is exactly what we want. As a result, we are passing in `suppress_st_warning=True` to turn that warning off.

ä½ ä¹Ÿè®¸å·²ç»æ³¨æ„åˆ°æˆ‘ä»¬æ·»åŠ `suppress_st_warning`å…³é”®å­—åˆ°`@st.cache`è£…é¥°å™¨ä¸Š. è¿™æ˜¯å› ä¸ºä¸Šè¿°ç¼“å­˜çš„å‡½æ•°ä½¿ç”¨äº†streamlitçš„st.write(), å½“streamlitæ£€æµ‹åˆ°è¿™ä¸ªå­˜åœ¨, åªæœ‰å½“ä½ é‡åˆ°ç¼“å­˜ä¸¢å¤±æ—¶, ä½ åªæœ‰æ‰§è¡Œä»£ç æ—¶å®ƒä¼šå±•ç¤ºä¸€ä¸ªè­¦å‘Š. é€šå¸¸æƒ…å†µä¸‹, å½“ä½ çœ‹åˆ°è¿™ä¸ªè­¦å‘Š, è¿™æ„å‘³ç€ä½ çš„ä»£ç å­˜åœ¨bug. 

## Example 2: When the function arguments change

æ¡ˆä¾‹2: å½“å‡½æ•°å‚æ•°æ”¹å˜

*æ³¨: å®˜æ–¹æ–‡æ¡£è§£é‡Šè¿™ä¸ªé—®é¢˜å¾ˆå•°å—¦æ··ä¹±, ç®€å•è€Œè¨€, `suppress_st_warning=True`å°±æ˜¯ç”¨æ¥ç©ºå€¼ç¼“å­˜ä¸¢å¤±è­¦å‘Šç”¨çš„.*

*å½“ä½ ä¿®æ”¹äº†å‡½æ•°ç›¸å…³çš„ä»£ç , å°±ä¼šå‡ºç°ç¼“å­˜ä¸¢å¤±çš„é—®é¢˜, å¦‚æœä¸å¸Œæœ›å‡ºç°è­¦å‘Š, å°±æ˜¯ç”¨è¿™ä¸ªflag.*

Without stopping the previous app server, let's change one of the arguments to our cached function:

æ²¡æœ‰åœæ­¢ä¸Šè¿°çš„appæœåŠ¡å™¨, ä¿®æ”¹ç¼“å­˜å‡½æ•°å…¶ä¸­çš„ä¸€ä¸ªå‚æ•°.

```python
import streamlit as st
import time

@st.cache(suppress_st_warning=True)
def expensive_computation(a, b):
    st.write("Cache miss: expensive_computation(", a, ",", b, ") ran")
    time.sleep(2)  # This makes the function take 2s to run
    return a * b

a = 2
b = 210  # ğŸ‘ˆ Changed this
res = expensive_computation(a, b)

st.write("Result:", res)
```

Now the first time you rerun the app it's a cache miss. This is evidenced by the "Cache miss" text showing up and the app taking 2s to finish running. After that, if you press **R** to rerun, it's always a cache hit. That is, no such text shows up and the app is fast again.

å½“ä½ ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶, ä¸Šè¿°æ–‡æœ¬ä¼šèŠ±è´¹2ç§’æ¥å±•ç¤ºè¿™æ–‡æœ¬. å½“ä½ é‡æ–°æŒ‰ä¸‹`R`é”®æ—¶, è¿™ä¸ªæ–‡æœ¬ä¸ä¼šå±•ç¤º, å› ä¸ºç¼“å­˜.

This is because Streamlit notices whenever the arguments **a** and **b** change and determines whether the function should be re-executed and re-cached.

## Example 3: When the function body changes

æ¡ˆä¾‹3: å½“å‡½æ•°çš„ä¸»ä½“å‘ç”Ÿæ”¹å˜

Without stopping and restarting your Streamlit server, let's remove the widget from our app and modify the function's code by adding a `+ 1` to the return value.

æ²¡æœ‰åœæ­¢å’Œé‡å¯streamlitæœåŠ¡å™¨, ç§»é™¤è¿™ä¸ªç»„ä»¶ä»appå½“ä¸­

```python
import streamlit as st
import time

@st.cache(suppress_st_warning=True)
def expensive_computation(a, b):
    st.write("Cache miss: expensive_computation(", a, ",", b, ") ran")
    time.sleep(2)  # This makes the function take 2s to run
    return a * b + 1  # ğŸ‘ˆ Added a +1 at the end here

a = 2
b = 210
res = expensive_computation(a, b)

st.write("Result:", res)
```

The first run is a "Cache miss", but when you press **R** each subsequent run is a cache hit. This is because on first run, Streamlit detected that the function body changed, reran the function, and put the result in the cache.

#### Tip

æç¤º

If you change the function back the result will already be in the Streamlit cache from a previous run. Try it out!

## Example 4: When an inner function changes

æ¡ˆä¾‹4: å½“ä¸€ä¸ªå†…éƒ¨å‡½æ•°æ”¹å˜

Let's make our cached function depend on another function internally:

è®©æˆ‘ä»¬åœ¨ç¼“å­˜ä¸€ä¸ªå‡½æ•°, å…¶å†…éƒ¨ä¾èµ–äºå¦ä¸€ä¸ªå‡½æ•°.

æ³¨: ç®€å•è€Œè¨€, å¤–éƒ¨çš„å‡½æ•°ä¿®æ”¹, ä¹Ÿä¼šå¼•å‘ç¼“å­˜ä¸¢å¤±çš„è­¦å‘Š, å¹¶ä¸éœ€è¦å®Œæ•´çš„åŒ…è£¹åœ¨è£…é¥°å™¨ä¸­(ä»£ç ä¸éœ€è¦å®Œå…¨åŒ…è£¹åœ¨è£…é¥°çš„å‡½æ•°å†…).

```python
import streamlit as st
import time

def inner_func(a, b):
    st.write("inner_func(", a, ",", b, ") ran")
    return a * b

@st.cache(suppress_st_warning=True)
def expensive_computation(a, b):
    st.write("Cache miss: expensive_computation(", a, ",", b, ") ran")
    time.sleep(2)  # This makes the function take 2s to run
    return inner_func(a, b) + 1

a = 2
b = 210
res = expensive_computation(a, b)

st.write("Result:", res)
```

What you see is the usual:

ä½ é€šå¸¸ä¼šçœ‹åˆ°

1. The first run results in a cache miss.
1. ç¬¬ä¸€æ¬¡è¿è¡Œæ‰å‡ºç°è¿™ä¸ªæç¤º
2. Every subsequent rerun results in a cache hit.
2. ä¹‹åçš„æ¯æ¬¡è¿è¡Œå°†ä¸ä¼šæœ‰è¿™ä¸ªæç¤º.

But now let's try modifying the `inner_func()`:

ä½†æ˜¯ç°åœ¨, ä¿®æ”¹`inner_func()`å‡½æ•°

```python
import streamlit as st
import time

def inner_func(a, b):
    st.write("inner_func(", a, ",", b, ") ran")
    return a ** b  # ğŸ‘ˆ Changed the * to ** here

@st.cache(suppress_st_warning=True)
def expensive_computation(a, b):
    st.write("Cache miss: expensive_computation(", a, ",", b, ") ran")
    time.sleep(2)  # This makes the function take 2s to run
    return inner_func(a, b) + 1

a = 2
b = 21
res = expensive_computation(a, b)

st.write("Result:", res)
```

Even though `inner_func()` is not annotated with [`@st.cache`](https://docs.streamlit.io/library/api-reference/performance/st.cache), when we edit its body we cause a "Cache miss" in the outer `expensive_computation()`.

å°½ç®¡`inner_func()`æ²¡æœ‰ä½¿ç”¨è£…é¥°å™¨, å½“æˆ‘ä»¬ç¼–è¾‘å®ƒçš„ä¸»ä½“æ—¶, 

That's because Streamlit always traverses your code and its dependencies to verify that the cached values are still valid. This means that while developing your app you can edit your code freely without worrying about the cache. Any change you make to your app, Streamlit should do the right thing!

è¿™æ˜¯å› ä¸ºstreamlitæ€»æ˜¯éå†ä»£ç ä»¥åŠä¾èµ–, ç”¨äºæ ¡éªŒç¼“å­˜å€¼æ˜¯å¦ä¾ç„¶æœ‰æ•ˆ. è¿™æ„å‘³ç€ä½ å¯ä»¥è‡ªç”±åœ°ç¼–è¾‘ä»£ç è€Œä¸éœ€è¦è€ƒè™‘ç¼“å­˜çš„é—®é¢˜(æ„æ€æ˜¯å½“ä½ ä¿®æ”¹äº†ä»£ç ä¹‹å, ç¼“å­˜å°±ä¼šå¤±æ•ˆ, è€Œä¸éœ€è¦æ‹…å¿ƒç¼“å­˜çš„å½±å“, ä¾‹å¦‚ä½ æ”¹äº†ä»£ç , ç†åº”è¿”å›ä¸ä¸€æ ·çš„å€¼, ä½†æ˜¯æ‹…å¿ƒç¼“å­˜çš„å½±å“).

æ³¨: è¿™æ„å‘³ç€å¯ä»¥çƒ­ç¼–ç¨‹, å³ä¸€è¾¹ä¿®æ”¹ä»£ç , ä¸€è¾¹è¿è¡ŒæŸ¥çœ‹, è€Œä¸éœ€è¦æ¯æ¬¡ä¿®æ”¹ä»£ç ä¹‹åé‡æ–°å¯åŠ¨streamlitæœåŠ¡å™¨.

Streamlit is also smart enough to only traverse dependencies that belong to your app, and skip over any dependency that comes from an installed Python library.

streamlitæ™ºèƒ½ç¨‹åº¦è¶³ä»¥åŒºåˆ†å¼€è‡ªæœ‰ä»£ç çš„ä¾èµ–å’ŒpythonåŸç”Ÿåº“çš„ä¾èµ–, åªéå†å±äºappè‡ªèº«çš„ä¾èµ–, ä¼šè·³è¿‡ä¸€ä¸ªå·²ç»å®‰è£…çš„pythonåº“(ç¬¬ä¸‰æ–¹è¿˜æ˜¯åŸç”Ÿ?)ä¾èµ–.

## Example 5: Use caching to speed up your app across users

æ¡ˆä¾‹5: ä½¿ç”¨ç¼“å­˜ä¸ºä¸åŒçš„ç”¨æˆ·åŠ é€Ÿapp

Going back to our original function, let's add a widget to control the value of `b`:

å›åˆ°æœ€åˆçš„å‡½æ•°, å¢åŠ ä¸€ä¸ªç»„ä»¶æ¥æ§åˆ¶å€¼`b`.

```python
import streamlit as st
import time

@st.cache(suppress_st_warning=True)
def expensive_computation(a, b):
    st.write("Cache miss: expensive_computation(", a, ",", b, ") ran")
    time.sleep(2)  # This makes the function take 2s to run
    return a * b

a = 2
b = st.slider("Pick a number", 0, 10)  # ğŸ‘ˆ Changed this
# å˜æ›´è¿™ä¸ªç¼“å­˜å°†ä¸¢å¤±
res = expensive_computation(a, b)

st.write("Result:", res)
```

What you'll see:

- If you move the slider to a number Streamlit hasn't seen before, you'll have a cache miss again. And every subsequent rerun with the same number will be a cache hit, of course.
- å½“ç§»åŠ¨æ»‘åŠ¨æ¡æ”¹å˜æ•°å­—æ—¶, å‡å¦‚è¿™ä¸ªæ•°å­—æ²¡æœ‰å‡ºç°è¿‡,  ç¼“å­˜ä¸¢å¤±å°†ä¼šå†æ¬¡å‡ºç°.
- If you move the slider back to a number Streamlit has seen before, the cache is hit and the app is fast as expected.
- å‡ºç°è¿‡, ä¹Ÿå°±æ„å‘³ç¼“å­˜çš„äº§ç”Ÿ

In computer science terms, what is happening here is that [`@st.cache`](https://docs.streamlit.io/library/api-reference/performance/st.cache) is [memoizing](https://en.wikipedia.org/wiki/Memoization) `expensive_computation(a, b)`.

ç”¨è®¡ç®—æœºæœ¯è¯­æ¥æè¿°, è¿™æ—¶å€™çš„è£…é¥°å™¨å®åœ¨è®°ä½è¿™ä¸ª`expensive_computation(a, b)`å‡½æ•°.

But now let's go one step further! Try the following:

1. Move the slider to a number you haven't tried before, such as 9.
2. Pretend you're another user by opening another browser tab pointing to your Streamlit app (usually at http://localhost:8501)
3. In the new tab, move the slider to 9.

Notice how this is actually a cache hit! That is, you don't actually see the "Cache miss" text on the second tab even though that second user never moved the slider to 9 at any point prior to this.

è¿™ç§ç¼“å­˜æ˜¯ä½œç”¨åœ¨å…¨å±€çš„, ä¸ç®¡æ˜¯ä¸€ä¸ªæµè§ˆå™¨å¼€å¤šä¸ªæ ‡ç­¾, è¿˜æ˜¯åœ¨ä¸åŒçš„æœºå™¨ä¸Šè®¿é—®, ç›¸å…³çš„å†…å®¹åªè¦è®¿é—®è¿‡, ç¼“å­˜çš„äº§ç”Ÿå°±æ˜¯ä½œç”¨åœ¨å…¨å±€çš„.

This happens because the Streamlit cache is global to all users. So everyone contributes to everyone else's performance.

ä¸€äººè´¡çŒ®å…¨å±€çš„æ•ˆç‡.

## Example 6: Mutating cached values

æ¡ˆä¾‹6: å¯å˜ä¸­çš„ç¼“å­˜å€¼

As mentioned in the [overview](https://docs.streamlit.io/library/advanced-features/caching#optimize-performance-with-stcache) section, the Streamlit cache stores items by reference. This allows the Streamlit cache to support structures that aren't memory-managed by Python, such as TensorFlow objects. However, it can also lead to unexpected behavior â€” which is why Streamlit has a few checks to guide developers in the right direction. Let's look into those checks now.

æ­£å¦‚åœ¨æ¦‚è¦ä¸­æ‰€æåŠçš„, streamlité€šè¿‡å¼•ç”¨æ¥å­˜å‚¨ç¼“å­˜. è¿™å…è®¸streamlitç¼“å­˜æ”¯æŒä¸æ˜¯pythonç®¡ç†çš„å†…å­˜ç»“æ„(å³è¯¥å¯¹è±¡çš„å†…å­˜ä¸æ˜¯pythonæ‰€ç®¡ç†çš„), ä¾‹å¦‚TensorFlowå¯¹è±¡. ç„¶è€Œè¿™ä¼šå¯¼è‡´ä¸å¯é¢„æµ‹çš„è¡Œä¸º, è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆstreamlit.

Let's write an app that has a cached function which returns a mutable object, and then let's follow up by mutating that object:

è®©æˆ‘ä»¬å†™ä¸€ä¸ªapp, è¿™æœ‰ä¸€ä¸ªç¼“å­˜å‡½æ•°, è¿™ä¸ªå‡½æ•°ä¼šè¿”å›ä¸€ä¸ªæ˜“å˜å€¼.

```python
import streamlit as st
import time
# @st.experimental_memo, è¿™ä¸ªè£…é¥°å™¨, å…¶æ•ˆæœä¹Ÿæ˜¯ä¸€æ ·çš„
# ä¸ä¼ å…¥è¿™ä¸ªå‚æ•°, suppress_st_warning=True, å°†ä¼šåœ¨ç•Œé¢ä¸Šå‡ºç°è­¦å‘Š
# @st.experimental_memo, ä¸å…·æœ‰è¿™ä¸ªå‚æ•°, ä¸ä¼šå‡ºç°è­¦å‘Š
@st.cache(suppress_st_warning=True)
def expensive_computation(a, b):
    st.write("Cache miss: expensive_computation(", a, ",", b, ") ran")
    time.sleep(2)  # This makes the function take 2s to run
    return {"output": a * b}  # ğŸ‘ˆ Mutable object

a = 2
b = 21
res = expensive_computation(a, b)

st.write("Result:", res)

res["output"] = "result was manually mutated"  # ğŸ‘ˆ Mutated cached value

st.write("Mutated result:", res)
```

When you run this app for the first time, you should see three messages on the screen:

- Cache miss (...)
- Result: {output: 42}
- Mutated result: {output: "result was manually mutated"}

No surprises here. But now notice what happens when you rerun you app (i.e. press **R**):

- Result: {output: "result was manually mutated"}
- Mutated result: {output: "result was manually mutated"}
- Cached object mutated. (...)

So what's up?

What's going on here is that Streamlit caches the output `res` by reference. When you mutated `res["output"]` outside the cached function you ended up inadvertently modifying the cache. This means every subsequent call to `expensive_computation(2, 21)` will return the wrong value!

è¿™é‡Œå‘ç”Ÿçš„äº‹æƒ…æ˜¯streamlitç¼“å­˜çš„ç»“æœæ˜¯é€šè¿‡å¼•ç”¨çš„æ–¹å¼æ¥å®ç°çš„. å½“ä½ åœ¨ç¼“å­˜å‡½æ•°å¤–éƒ¨ä¿®æ”¹ç¼“å­˜å¯¹è±¡, ä½ ä¹Ÿåœ¨æ— æ„ä¸­ä¿®æ”¹äº†ç¼“å­˜ä¸­çš„å¯¹è±¡.è¿™å°±æ„å‘³ç€ä½ ä¹‹åçš„æ¯ä¸€æ¬¡è°ƒç”¨ç¼“å­˜å‡½æ•°, è¿”å›çš„éƒ½æ˜¯é”™è¯¯çš„å€¼.

Since this behavior is usually not what you'd expect, Streamlit tries to be helpful and show you a warning, along with some ideas about how to fix your code.

In this specific case, the fix is just to not mutate `res["output"]` outside the cached function. There was no good reason for us to do that anyway! Another solution would be to clone the result value with `res = deepcopy(expensive_computation(2, 21))`. Check out the section entitled [Fixing caching issues](https://docs.streamlit.io/knowledge-base/using-streamlit/caching-issues) for more information on these approaches and more.



## Advanced caching

é«˜é˜¶ç¼“å­˜

In [caching](https://docs.streamlit.io/library/advanced-features/caching), you learned about the Streamlit cache, which is accessed with the [`@st.cache`](https://docs.streamlit.io/library/api-reference/performance/st.cache) decorator. In this article you'll see how Streamlit's caching functionality is implemented, so that you can use it to improve the performance of your Streamlit apps.

The cache is a key-value store, where the key is a hash of:

ç¼“å­˜æ˜¯ä»¥é”®å€¼çš„å½¢å¼å­˜åœ¨çš„, é”®æ˜¯ä½¿ç”¨ä¸‹é¢æåŠå†…å®¹ä½œä¸ºå“ˆå¸Œå€¼çš„.

1. The input parameters that you called the function with
2. The value of any external variable used in the function
3. The body of the function
4. The body of any function used inside the cached function

And the value is a tuple of:

è¿™é‡Œçš„å€¼æ˜¯å…ƒç»„çš„å½¢å¼

- The cached output, ç¼“å­˜çš„ç»“æœ
- A hash of the cached output (you'll see why soon), ç¼“å­˜ç»“æœçš„hash

For both the key and the output hash, Streamlit uses a specialized hash function that knows how to traverse code, hash special objects, and can have its [behavior customized by the user](https://docs.streamlit.io/library/advanced-features/caching#the-hash_funcs-parameter).

å¯¹äºé”®å’Œè¾“å‡ºå“ˆå¸Œ, streamlitä½¿ç”¨äº†ä¸“é—¨çš„å“ˆå¸Œå‡½æ•°, è¿™ä¸ªå‡½æ•°çŸ¥é“å¦‚ä½•éå†ä»£ç , å“ˆå¸ŒæŒ‡å®šçš„å¯¹è±¡, è¿™ä¸ªå‡½æ•°ä¹Ÿå¯ä»¥ç”¨æˆ·è‡ªå®šä¹‰(ä¹Ÿå°±æ˜¯è®¡ç®—å“ˆå¸Œçš„æ–¹å¼, ç”¨æˆ·å¯ä»¥è‡ªå®šä¹‰, å³ç”¨æˆ·å¸Œæœ›streamlité€šè¿‡ä½•ç§æ–¹å¼å®ç°è¿™ä¸ªå“ˆå¸Œçš„è®¡ç®—, é—´æ¥å®ç°æ§åˆ¶è¢«è£…é¥°çš„å‡½æ•°çš„åŠ è½½æƒ…å†µ).

For example, when the function `expensive_computation(a, b)`, decorated with [`@st.cache`](https://docs.streamlit.io/library/api-reference/performance/st.cache), is executed with `a=2` and `b=21`, Streamlit does the following:

ä¾‹å¦‚, å½“è¢«è£…é¥°çš„å‡½æ•°è¢«æ‰§è¡Œæ—¶, streamlitä¼šæ‰§è¡Œä»¥ä¸‹æ“ä½œ.

1. Computes the cache key

1. è®¡ç®—ç¼“å­˜é”®å“ˆå¸Œ

2. If the key is found in the cache, then:

   å¦‚æœé”®å­˜åœ¨åœ¨ç¼“å­˜ä¸­

   - Extracts the previously-cached (output, output_hash) tuple.

   - å–å‡ºä¹‹å‰çš„ç¼“å­˜å€¼(ä»¥å…ƒç»„æ–¹å¼)

   - Performs an Output Mutation Check, where a fresh hash of the output is computed and compared to the stored

      æ‰§è¡Œä¸€ä¸ªè¾“å‡ºç»“æœå¯å˜æ£€æµ‹, è¾“å‡ºå†…å®¹æ–°çš„å“ˆå¸Œå€¼ä¼šè¢«è®¡ç®—å’Œå·²å­˜å‚¨çš„ç›¸æ¯”è¾ƒ

     (è¿™æ˜¯å› ä¸ºç¼“å­˜ä¿æŒçš„æ˜¯å¼•ç”¨å€¼, è€Œå¯å˜å¯¹è±¡, å¼•ç”¨å€¼ä¸å‘ç”Ÿæ”¹å˜çš„å‰æä¸‹, å…¶å†…å®¹ä¹Ÿå¯èƒ½å‘ç”Ÿæ”¹å˜, æ‰€ä»¥éœ€è¦æ‰§è¡Œè¿™ä¸€æ­¥æ¥æ ¡æ£€å‰åå†…å®¹çš„ä¸€è‡´)

     - If the two hashes are different, shows a **Cached Object Mutated** warning. (Note: Setting `allow_output_mutation=True` disables this step).
   - å¦‚æœå“ˆå¸Œå­˜åœ¨å·®å¼‚, å°†è§¦å‘å¯å˜ç¼“å­˜å¯¹è±¡è­¦å‘Š(æ³¨: å¯ä»¥å–æ¶ˆæ‰è¯¥è­¦å‘Š, ä½¿ç”¨å‚æ•°: allow_output_mutation=True)
   
4. If the input key is not found in the cache, then:

   å¦‚æœè¾“å‡ºçš„é”®æ²¡æœ‰å‘ç°åœ¨ç¼“å­˜ä¸­

   - Executes the cached function (i.e. `output = expensive_computation(2, 21)`).
   - æ‰§è¡Œç¼“å­˜å‡½æ•°
   - Calculates the `output_hash` from the function's `output`.
   - è®¡ç®—è¾“å‡ºç»“æœçš„hash
   - Stores `key â†’ (output, output_hash)` in the cache.
   - å­˜å‚¨é”®å€¼å“ˆå¸Œ

5. Returns the output.

4. è¿”å›ç»“æœ

If an error is encountered an exception is raised. If the error occurs while hashing either the key or the output an `UnhashableTypeError` error is thrown. If you run into any issues, see [fixing caching issues](https://docs.streamlit.io/knowledge-base/using-streamlit/caching-issues).

å¦‚æœé‡åˆ°é”™è¯¯, å°†è§¦å‘å¼‚å¸¸. å¦‚æœé”™è¯¯æ—¶åœ¨é”®å’Œç»“æœè¿›è¡Œå“ˆå¸Œè®¡ç®—æ—¶è§¦å‘çš„, å°†ä¼šæŠ›å‡ºä¸å¯å“ˆå¸Œç±»å‹é”™è¯¯.

### The hash_funcs parameter

hashå‡½æ•°çš„å‚æ•°

æ³¨: è¿™é‡Œå®é™…ä¸Šæ¶‰åŠçš„æ˜¯, è‡ªå®šä¹‰å“ˆå¸Œå‡½æ•°

As described above, Streamlit's caching functionality relies on hashing to calculate the key for cached objects, and to detect unexpected mutations in the cached result.

å¦‚ä¸Šæ‰€è¿°, streamlitç¼“å­˜åŠŸèƒ½æ˜¯åŸºäºè®¡ç®—ç¼“å­˜å¯¹è±¡çš„å“ˆå¸Œå€¼ä½œä¸ºé”®. ä»¥æ£€æµ‹ç¼“å­˜å†…å®¹æ˜¯å¦å‘ç”Ÿæ”¹å˜

For added expressive power, Streamlit lets you override this hashing process using the `hash_funcs` argument. Suppose you define a type called `FileReference` which points to a file in the filesystem:

ä¸ºäº†å¢å¼ºå¯ç”¨æ€§, streamlitå…è®¸ä½ é‡å†™å“ˆå¸Œå‡½æ•°ç”¨`hash_funcs`å‚æ•°. å‡å¦‚ä½ å¯ä»¥å®šä¹‰ä¸€ä¸ªç±»å‹åä¸ºæ–‡ä»¶å¼•ç”¨(`FileReference`), è¿™æ˜¯æŒ‡å‘æ–‡ä»¶ç³»ç»Ÿä¸­çš„ä¸€ä¸ªæ–‡ä»¶.

```python
class FileReference:
    def __init__(self, filename):
        self.filename = filename


@st.cache
def func(file_reference):
    ...
```

By default, Streamlit hashes custom classes like `FileReference` by recursively navigating their structure. In this case, its hash is the hash of the filename property. As long as the file name doesn't change, the hash will remain constant.

é»˜è®¤çŠ¶æ€ä¸‹, streamlitå“ˆå¸Œè‡ªå®šä¹‰çš„ç±», åƒ `FileReference`, é€šè¿‡é€’å½’çš„æ–¹å¼æ¥éå†å…¶ç»“æ„. åœ¨æŸäº›æƒ…å†µä¸‹, è¿™ä¸ªå“ˆå¸Œå€¼å¯ä»¥æ˜¯æ–‡ä»¶åå±æ€§çš„å“ˆå¸Œå€¼. åªè¦æ–‡ä»¶åä¸å‘ç”Ÿæ”¹å˜, å“ˆå¸Œå€¼å°±ä¸€ç›´ä¸å˜.

However, what if you wanted to have the hasher check for changes to the file's modification time, not just its name? This is possible with [`@st.cache`](https://docs.streamlit.io/library/api-reference/performance/st.cache)'s `hash_funcs` parameter:

ç„¶å, å¦‚æœä½ æƒ³å¸Œæœ›è¿™ä¸ªå“ˆå¸Œå‡½æ•°å»æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹çš„æ—¶é—´, è€Œä¸ä»…ä»…æ˜¯æ–‡ä»¶å. 

```python
class FileReference:
    def __init__(self, filename):
        self.filename = filename

def hash_file_reference(file_reference):
    filename = file_reference.filename
    return (filename, os.path.getmtime(filename))

@st.cache(hash_funcs={FileReference: hash_file_reference})
def func(file_reference):
    ...
```

Additionally, you can hash `FileReference` objects by the file's contents:

æ­¤å¤–ä½ ä¹Ÿå¯ä»¥å“ˆå¸Œ`FileReference`å¯¹è±¡é€šè¿‡æ–‡ä»¶çš„å†…å®¹

```python
class FileReference:
    def __init__(self, filename):
        self.filename = filename

def hash_file_reference(file_reference):
    with open(file_reference.filename) as f:
      return f.read()

@st.cache(hash_funcs={FileReference: hash_file_reference})
def func(file_reference):
    ...
```

#### Note

æ³¨æ„

Because Streamlit's hash function works recursively, you don't have to hash the contents inside `hash_file_reference` Instead, you can return a primitive type, in this case the contents of the file, and Streamlit's internal hasher will compute the actual hash from it.

å› ä¸ºstreamlitå“ˆå¸Œå‡½æ•°æ˜¯ä»¥é€’å½’æ–¹å¼è¿è¡Œçš„, 

### Typical hash functions

While it's possible to write custom hash functions, let's take a look at some of the tools that Python provides out of the box. Here's a list of some hash functions and when it makes sense to use them.



Python's [`id`](https://docs.python.org/3/library/functions.html#id) function | [Example](https://docs.streamlit.io/library/advanced-features/caching#example-1-pass-a-database-connection-around)

- Speed: Fast
- Use case: If you're hashing a singleton object, like an open database connection or a TensorFlow session. These are objects that will only be instantiated once, no matter how many times your script reruns.
- ä½¿ç”¨åœºæ™¯: å¦‚æœä½ æ­£åœ¨å“ˆå¸Œä¸€ä¸ªå•ä¾‹å¯¹è±¡, å¦‚æ•°æ®åº“è¿æ¥å®ä¾‹, æˆ–è€…TensorFlowä¼šè¯. è¿™äº›å¯¹è±¡åªä¼šå®ä¾‹åŒ–ä¸€æ¬¡, ä¸ç®¡ä½ çš„è„šæœ¬è¿è¡Œå¤šå°‘æ¬¡.

`lambda _: None` | [Example](https://docs.streamlit.io/library/advanced-features/caching#example-2-turn-off-hashing-for-a-specific-type)

- Speed: Fast
- Use case: If you want to turn off hashing of this type. This is useful if you know the object is not going to change.
- ä½ å¸Œæœ›å…³é—­é’ˆå¯¹ç‰¹å®šç±»å‹çš„å“ˆå¸ŒåŠŸèƒ½. è¿™éå¸¸æœ‰ç”¨å¦‚æœä½ çŸ¥é“è¿™ä¸ªå¯¹è±¡ä¸ä¼šå‘ç”Ÿæ”¹å˜.

Python's [`hash()`](https://docs.python.org/3/library/functions.html#hash) function | [Example](https://docs.streamlit.io/library/advanced-features/caching#example-3-use-pythons-hash-function)

- Speed: Can be slow based the size of the object being cached
- é€Ÿåº¦, å¿«æ…¢å’Œç¼“å­˜å¯¹è±¡çš„å¤§å°æœ‰å…³
- Use case: If Python already knows how to hash this type correctly.
- ä½¿ç”¨åœºæ™¯, 

Custom hash function | [Example](https://docs.streamlit.io/library/advanced-features/caching#the-hash_funcs-parameter)

- Speed: N/a
- é€Ÿåº¦: æœªçŸ¥
- Use case: If you'd like to override how Streamlit hashes a particular type.
- ä½¿ç”¨åœºæ™¯:  å¸Œæœ›é‡å†™streamlit hashå‡½æ•°é’ˆå¯¹ç‰¹å®šçš„ç±»å‹.

### Example 1: Pass a database connection around

æ¡ˆä¾‹1: ä¼ é€’æ•°æ®åº“è¿æ¥å®ä¾‹

Suppose we want to open a database connection that can be reused across multiple runs of a Streamlit app. For this you can make use of the fact that cached objects are stored by reference to automatically initialize and reuse the connection:

å‡è®¾æˆ‘ä»¬æƒ³æ‰“å¼€ä¸€ä¸ªæ•°æ®åº“è¿æ¥, å¯ä»¥åœ¨streamlit appå¤šæ¬¡è¿è¡Œä¸­å¯ä»¥é‡å¤ä½¿ç”¨.

```python
@st.cache(allow_output_mutation=True)
def get_database_connection():
    return db.get_connection()
```

With just 3 lines of code, the database connection is created once and stored in the cache. Then, every subsequent time `get_database_conection` is called, the already-created connection object is reused automatically. In other words, it becomes a singleton.

åªéœ€è¦3è¡Œä»£ç , æ•°æ®åº“è¿æ¥å°±å¯ä»¥ä¸€æ¬¡æ€§åˆ›å»ºå’Œç¼“å­˜. ä¹‹åçš„æ¯æ¬¡`get_database_conection`è°ƒç”¨, è¿™ä¸ªæ—©å·²ç»åˆ›å»ºçš„è¿æ¥å¯¹è±¡å°†è‡ªåŠ¨å¯ä»¥å¤ç”¨. æ¢è¨€ä¹‹, è¿™ä¸ªå¯¹è±¡æˆä¸ºäº†å•ä¾‹.

#### Tip

æç¤º

Use the `allow_output_mutation=True` flag to suppress the immutability check. This prevents Streamlit from trying to hash the output connection, and also turns off Streamlit's mutation warning in the process.

ä½¿ç”¨`allow_output_mutation=True`æ ‡è®°é˜»æ­¢ä¸å˜æ€§(`immutability`)æ£€æŸ¥. è¿™æ˜¯é˜²æ­¢streamlitå°è¯•å»hashè¿™ä¸ªè¾“å‡ºè¿æ¥, åŒæ—¶è¿™ä¸ªæ ‡è®°åŒæ ·ä¼šå…³é—­å¯å˜(å¯¹è±¡)è­¦å‘Š.

What if you want to write a function that receives a database connection as input? For that, you'll use `hash_funcs`:

å¦‚æœä½ æƒ³å†™ä¸€ä¸ªå‡½æ•°ç”¨äºæ¥æ”¶ä¸€ä¸ªæ•°æ®åº“è¿æ¥ä½œä¸ºè¾“å…¥? è¿™ä¸ªæ—¶å€™å¯ä»¥ä½¿ç”¨`hash_funcs`.

```python
@st.cache(hash_funcs={DBConnection: id})
def get_users(connection):
    # Note: We assume that connection is of type DBConnection.
    return connection.execute_sql('SELECT * from Users')
```

Here, we use Python's built-in `id` function, because the connection object is coming from the Streamlit cache via the `get_database_conection` function. This means that the same connection instance is passed around every time, and therefore it always has the same id. However, if you happened to have a second connection object around that pointed to an entirely different database, it would still be safe to pass it to `get_users` because its id is guaranteed to be different than the first id.

è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨pythonå†…ç½®çš„idå‡½æ•°, å› ä¸ºè¿™ä¸ªè¿æ¥å¯¹è±¡æ¥è‡ªstreamlitç¼“å­˜, é€šè¿‡`get_database_conection`. è¿™æ„å‘³ç€æ¯æ¬¡ä¼ é€’çš„éƒ½æ˜¯ç›¸åŒçš„è¿æ¥å®ä¾‹å¯¹è±¡, å› æ­¤æ¯æ¬¡éƒ½éƒ½æ˜¯ç›¸åŒçš„id. 

These design patterns apply any time you have an object that points to an external resource, such as a database connection or Tensorflow session.



### Example 2: Turn off hashing for a specific type

æ¡ˆä¾‹2: å¯¹ç‰¹å®šçš„ç±»å‹å…³é—­hashåŠŸèƒ½

You can turn off hashing entirely for a particular type by giving it a custom hash function that returns a constant. One reason that you might do this is to avoid hashing large, slow-to-hash objects that you know are not going to change. For example:

ä½ å¯ä»¥æ•´ä½“å…³é—­hashé’ˆå¯¹ç‰¹å®šçš„ç±»å‹, é€šè¿‡ä¸€ä¸ªè‡ªå®šä¹‰hashå‡½æ•°è¿”å›ä¸€ä¸ªå¸¸é‡.

æ³¨: å³ä¸å¸Œæœ›å¯¹æŸäº›ä¼ å…¥ç±»å‹äº§ç”Ÿç¼“å­˜

```python
@st.cache(hash_funcs={pd.DataFrame: lambda _: None})
def func(huge_constant_dataframe):
    ...
```

When Streamlit encounters an object of this type, it always converts the object into `None`, no matter which instance of `FooType` its looking at. This means all instances are hash to the same value, which effectively cancels out the hashing mechanism.

å½“streamlité‡åˆ°è¿™ç§ç±»å‹çš„å¯¹è±¡(æ³¨: æ‰‹åŠ¨æ ‡è®°è¿™ç§ç±»å‹), å®ƒé€šå¸¸ä¼šå°†è¿™ä¸ªå¯¹è±¡è½¬ä¸º`None`, ä¸ç®¡`FooType`çš„å®ä¾‹ç±»å‹æ˜¯å“ªç§. è¿™æ„å‘³ç€æ‰€æœ‰çš„å®ä¾‹å¾—åˆ°ç›¸åŒçš„hashå€¼, è¿™å°±ç›¸å½“äºå–æ¶ˆå“ˆå¸Œçš„æœºåˆ¶.

### Example 3: Use Python's hash() function

æ¡ˆä¾‹3: ä½¿ç”¨pythonå†…ç½®hashå‡½æ•°

Sometimes, you might want to use Pythonâ€™s default hashing instead of Streamlit's. For example, maybe you've encountered a type that Streamlit is unable to hash, but it's hashable with Python's built-in `hash()` function:

æœ‰æ—¶, ä½ ä¹Ÿè®¸æƒ³ä½¿ç”¨pythoné»˜è®¤çš„hashåŠŸèƒ½æ¥å–ä»£streamlitå†…ç½®çš„. ä¾‹å¦‚ä½ ä¹Ÿè®¸ä¼šé‡åˆ°streamlitå†…ç½®hashæ— æ³•å¤„ç†çš„æ•°æ®ç±»å‹, ä½†æ˜¯å¯ä»¥ç”¨pythonå†…ç½®çš„hashæ¥å¤„ç†çš„æƒ…å†µ.

```python
@st.cache(hash_funcs={FooType: hash})
def func(...):
    ...
```