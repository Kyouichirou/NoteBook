# streamlit实验性缓存接口(primitives)

Experimental cache primitives

## Overview

概述

Streamlit's unique execution model is a part of what makes it a joy to use: your code executes from top to bottom like a simple script for every interaction. There's no need to think about models, views, controllers, or anything of the sort.

streamlit的独特的执行模式让它在使用时看起来非常搞笑, 每次交互, 代码会像一个普通的脚本一样被从头到尾执行一遍.

Whenever your code re-executes, a decorator called [`@st.cache`](https://docs.streamlit.io/library/api-reference/performance/st.cache)—which is a powerful primitive for memoization and state storage capabilities—provides a caching mechanism that allows your app to stay performant even when loading data from the web, manipulating large datasets, or performing expensive computations.

不管什么时候, 当你的代码重新执行时, 这个名为@st.cache装饰器, 具有非常强大的用于存储, 状态保持能力, 这套缓存机制允许代码维持高效在加载数据从网络或者计算密集型的数据集.

However, we've found that [`@st.cache`](https://docs.streamlit.io/library/advanced-features/caching) is hard to use and not fast. You're either faced with cryptic errors like `InternalHashError` or `UnhashableTypeError`. Or you need to understand concepts like [`hash_funcs`](https://docs.streamlit.io/library/advanced-features/caching#the-hash_funcs-parameter) and [`allow_output_mutation`](https://docs.streamlit.io/library/advanced-features/caching#example-1-pass-a-database-connection-around)

然而我们发现`@st.cache`非常难用, 而且运行也不快.  你通常会碰到奇怪的错误, 像`InternalHashError`和`UnhashableTypeError`. 同时你还需要连接项`hash_funcs`和`allow_output_mutation`这些概念.

Our solutions include two new primitives: [**`st.experimental_memo`**](https://docs.streamlit.io/library/api-reference/performance/st.experimental_memo) and [**`st.experimental_singleton`**](https://docs.streamlit.io/library/api-reference/performance/st.experimental_singleton). They're conceptually simpler and much, much faster. In some of our internal tests on caching large dataframes, `@st.experimental_memo` has outperformed `@st.cache` by an order of magnitude. That's over 10X faster! 🚀

我们的解决方案包括两套机制, [**`st.experimental_memo`**](https://docs.streamlit.io/library/api-reference/performance/st.experimental_memo) and [**`st.experimental_singleton`**](https://docs.streamlit.io/library/api-reference/performance/st.experimental_singleton), 二者在概念上更易于理解和运行速度更快. 在一些内部测试中, 新的机制比`@st.cache`快上数十倍, 在加载大型数据集时, `@st.experimental_memo` 比 `@st.cache`快上一个数量级.

Let's take a look at the use-cases these *two* experimental APIs serve, and how they're a significant improvement over `@st.cache`.

让我们来看看这两个实验性API接口, 看这两个接口如何相比于@st.cache有巨大的性能提升.

*primitives: 是指由若干多机器指令构成的完成某种特定功能的一段程序, 具有不可分割性; 即原语的执行必须是连续的, 在执行过程中不允许被中断.*

## Problem

问题

`@st.cache` was serving the following use-cases:

1. Storing computation results given different kinds of inputs. In Computer Science literature, this is called [**memoization**](https://en.wikipedia.org/wiki/Memoization).
1. 存储给定不同类型输入的计算结果, 这在计算机术语中被称为记忆.
2. Initializing an object exactly once, and reusing that same instance on each rerun for the Streamlit server's lifetime. This is called the [**singleton pattern**](https://en.wikipedia.org/wiki/Singleton_pattern).
2. 一旦对象初始化, 在streamlit服务生命周期里, 每次返回的都是相同的实例, 这被称作单例模式.
3. Storing global state to be shared and modified across multiple Streamlit sessions (and, since Streamlit is threaded, you need to pay special attention to thread-safety).
3. 存储全局状态用于在多个会话中分享.

As a result of `@st.cache` trying to cover too many use-cases under a single unified API, it's both slow and complex.

由于@st.cache尝试处理不同的情况都使用单一不区分的API, 这使得代码运行非常慢和复杂.

## Solution

解决方案

While `@st.cache` tries to solve two very different problems simultaneously (caching data and sharing global singleton objects), these new primitives simplify things by dividing the problem across two different APIs. As a result, they are faster and simpler.

@st.cache尝试用于同时解决两个问题, 缓存数据和分享全局单例变量. 这里有新的机制来简化这些事情, 通过两个API将问题分别开来. 使得代码运行更快和更简单.

### `@st.experimental_memo`

Use [`@st.experimental_memo`](https://docs.streamlit.io/library/api-reference/performance/st.experimental_memo) to store expensive computation which can be "cached" or "memoized" in the traditional sense. It has almost the exact same API as the existing `@st.cache`, so you can often blindly replace one for the other:

使用`@st.experimental_memo`用于存储计算密集内容, 通常意义上可以被视作缓存或者记忆. 这几乎和`@st.cache`一样的, 在使用上可以直接取代`@st,cache`即可.

```python
import streamlit as st

@st.experimental_memo
def factorial(n):
    if n < 1:
        return 1
    return n * factorial(n - 1)

f10 = factorial(10)
f9 = factorial(9)  # Returns instantly!
```

#### Properties

属性

- Unlike `@st.cache`, this returns cached items by value, not by reference. This means that you no longer have to worry about accidentally mutating the items stored in the cache. Behind the scenes, this is done by using Python's `pickle()` function to serialize/deserialize cached values.
- 不像`@st.cache`, `@st.experimental_memo`返回的是对应项的值而不是引用. 这意味着不再需要担心意外修改了缓存中的可变对象.  在这背后, 这是由python的pickle函数负责序列化和解序列化缓存的值.
- Although this uses a custom hashing solution for generating cache keys (like `@st.cache`), it does ***not*** use `hash_funcs` as an escape hatch for unhashable parameters. Instead, we allow you to ignore unhashable parameters (e.g. database connections) by prefixing them with an underscore.
- 尽管`st.experimental_memo`使用了自定义的`hash`解决方案用于产生缓存键, 但是它不使用`hash_funcs`来转义接口(`hatch`)用于处理不可哈希的参数. 相反我们允许你忽视不可哈希的(`unhashable`)参数通过增加下划线和前置参数, 例如数据库连接实例.

For example:

```python
import streamlit as st
import pandas as pd
from sqlalchemy.orm import sessionmaker

@st.experimental_memo
def get_page(_sessionmaker, page_size, page):
    """Retrieve rows from the RNA database, and cache them.

    Parameters
    ----------
    _sessionmaker : a SQLAlchemy session factory. Because this arg name is
                    prefixed with "_", it won't be hashed.
    page_size : the number of rows in a page of result
    page : the page number to retrieve

    Returns
    -------
    pandas.DataFrame
    A DataFrame containing the retrieved rows. Mutating it won't affect
    the cache.
    """
    with _sessionmaker() as session:
        query = (
            session
                .query(RNA.id, RNA.seq_short, RNA.seq_long, RNA.len, RNA.upi)
                .order_by(RNA.id)
                .offset(page_size * page)
                .limit(page_size)
        )

        return pd.read_sql(query.statement, query.session.bind)
```

### `@st.experimental_singleton`

[`@st.experimental_singleton`](https://docs.streamlit.io/library/api-reference/performance/st.experimental_singleton) is a key-value store that's shared across all sessions of a Streamlit app. It's great for storing heavyweight singleton objects across sessions (like TensorFlow/Torch/Keras sessions and/or database connections).

`@st.experimental_singleton`在整个会话期间以键值方式存储相关的内容. 这对于存储重型(`heavyweight`)单例对象非常有益在跨会话中(像TensorFlow, Torch..或者数据库连接).

Example usage:

案例

```python
import streamlit as st
from sqlalchemy.orm import sessionmaker

@st.experimental_singleton
def get_db_sessionmaker():
    # This is for illustration purposes only
    DB_URL = "your-db-url"
    engine = create_engine(DB_URL)
    return sessionmaker(engine)

dbsm = get_db_sessionmaker()
```

#### How this compares to `@st.cache`:

对比与`@st.cache`

- Like `@st.cache`, **this returns items by reference.**
- 和`@st.cache`相似, 都是返回项的引用
- You can return any object type, including objects that are not serializable.
- 可以返回任意对象类型, 包括无法序列化的对象(***注意这个是重点***)
- Unlike `@st.cache`, this decorator does not have additional logic to check whether you are unexpectedly mutating the cached object. That logic was slow and produced confusing error messages. So, instead, we're hoping that by calling this decorator "singleton," we're nudging you to the correct behavior.
- 不像`@st.cache`, `st.experimental_singleton`不会有额外逻辑用于检测意外改变缓存的对象. 这个逻辑执行速度非常慢同时还会产生令人困惑的错误信息. 所以我们希望通过这个称为单例的装饰器用于纠正你正确行为.
- This does not follow the computation graph.
- 这与计算图不符(这句话不清楚作者的意图具体表示什么).
- You don't have to worry about `hash_funcs`! Just prefix your arguments with an underscore to ignore them.
- 不必要担心`hash_funcs`, 只要在你的参数前加上下划线就可以忽略它们.

#### Warning

警告

Singleton objects can be used concurrently by every user connected to your app, and *you are responsible for ensuring that `@st.singleton` objects are thread-safe*. (Most objects you'd want to stick inside an `@st.singleton` annotation are probably already safe—but you should verify this.)

单例模式对象可以被连接到app的用户同时使用. 你应该确保使用单例装饰器的对象时线程安全的.(大部分的对象, 你不想放到装饰器(函数)里面, 这些对象可能是安全的, 但是你应该验证).

### Which to use: memo or singleton?

该用哪种, `memo`还是`singleton`?

Decide between `@st.experimental_memo` and `@st.experimental_singleton` based on your function's *return type*. Functions that return *data* should use `memo`. Functions that return *non-data objects* should use `singleton`.

使用`@st.experimental_memo`或 `@st.experimental_singleton` , 这取决于你的函数返回的内容的类型. 当返回数据时, 使用`memo`, 返回的是非数据, 这使用单例`singleton`.

For example:

使用示例

- Dataframe computation (pandas, numpy, etc): this is *data—*use `memo`
- pandas, numpy的dataframe计算数据, memo
- Storing downloaded data: `memo`
- 存储已下载的数据, memo
- Calculating pi to n digits: `memo`
- 计算n位的pi值(圆周率)
- Tensorflow session: this is a *non-data object—*use `singleton`
- TensorFlow会话, 这是非数据对象, 使用单例.
- Database connection: `singleton`
- 数据库连接(这个是重点), singleton(单例)

### Clear memo and singleton caches procedurally

程序化清除记忆和单例缓存

You can clear caches of functions decorated with `@st.experimental_memo` and `@st.experimental_singleton` *in code*. For example, you can do the following:

你可以清除`@st.experimental_memo` 和 `@st.experimental_singleton`装饰器装饰的函数缓存在代码中. 例如:

```python
@st.experimental_memo
def square(x):
    return x**2

if st.button("Clear Square"):
    # Clear square's memoized values:
    square.clear()

if st.button("Clear All"):
    # Clear values from *all* memoized functions:
    st.experimental_memo.clear()
```

Pressing the "Clear Square" button will clear `square()`'s memoized values. Pressing the "Clear All" button will clear memoized values from all functions decorated with `@st.experimental_memo`.

按下清除按钮将清除`square()`函数缓存的值. 按下清除全部的按钮将清除掉所有使用@st.experimental_memo装饰器的函数的缓存值.

In summary:

总结:

- Any function annotated with `@st.experimental_memo` or `@st.experimental_singleton` gets its own `clear()` function automatically.
- 所有@st.experimental_memo` or `@st.experimental_singleton`装饰的函数都将自动获得clear()方法.
- Additionally, you can use [`st.experimental_memo.clear()`](https://docs.streamlit.io/library/api-reference/performance/st.experimental_memo.clear) and [`st.experimental_singleton.clear()`](https://docs.streamlit.io/library/api-reference/performance/st.experimental_singleton.clear) to clear *all* memo and singleton caches, respectively.
- 此外也可以使用[`st.experimental_memo.clear()`](https://docs.streamlit.io/library/api-reference/performance/st.experimental_memo.clear) and [`st.experimental_singleton.clear()`](https://docs.streamlit.io/library/api-reference/performance/st.experimental_singleton.clear)分别清除所有记忆和单例缓存.

#### Note

注意

The commands are **experimental**, so they're governed by our [experimental API process](https://docs.streamlit.io/library/advanced-features/prerelease#experimental).

这些是实验性的, 他们受到实验性API进程的管控.

These specialized **memoization** and **singleton** commands represent a big step in Streamlit's evolution, with the potential to *entirely replace* `@st.cache` at some point in 2022.

这些针对性的记忆(memoization)和单例(singleton)命令代表着streamlit进化的一大步, 将在2022年可能完全替代@st.cache装饰器在某些方面.

注: [memoization](https://zhuanlan.zhihu.com/p/56353893)

Yes, today you may use `@st.cache` for storing data you pulled in from a database connection (for a Tensorflow session, for caching the results of a long computation like changing the datetime values on a pandas dataframe, etc.). But these are very different things, so we made two new functions that will make it much faster! 💨

当然, 你现在依然还在使用@st.cache装饰器用于存储加载自诸如TensorFlow, 或者其他需要耗费时间计算得到结果的数据, 但是这里有了很大的不同, 这两种不同的功能将让代码运行更快.

Please help us out by testing these commands in real apps and leaving comments in [the Streamlit forums](https://discuss.streamlit.io/).